# AQI Prediction Model Using Python
* PM2.5 PM10
* NO,NO2
* NH3-Ammonia
* CO
* SO2
* O3
* Benzene,Toulene,Xylene
#Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from warnings import filterwarnings
filterwarnings('ignore')
df=pd.read_csv('air quality data (1).csv')
df.head()  #Top 5 rows
#shape- rows and colms!
df.shape
#Information
df.info()
#To know duplicate values
df.duplicated().sum()
#To check missing values
df.isnull().sum()
#Drop the rows where AQI is missing
df.dropna(subset=['AQI'],inplace = True)
df.isnull().sum().sort_values(ascending=False)

df.shape
#Summary of statistics in the dataset
df.describe().T
#Percentage of null values
null_values_percentage = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)
null_values_percentage
## Key consideration:
* Xylene has the highest percentage of missing values-61.86%
* PM10 and NH3 28-26%
## Week 2 - Visualization
# univariate analysis
df['Xylene'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['PM10'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['NH3'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['Toluene'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['Benzene'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['NOx'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['O3'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['PM2.5'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['SO2'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['CO'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# univariate analysis
df['AQI'].plot(kind ='hist',figsize=(10,5))
plt.legend()
plt.show()
# Distribution of AQI 2015-2020
sns.displot(df, x='AQI',color='purple')
plt.show
# Bivariate 
sns.set_theme(style="darkgrid")
graph=sns.catplot(x="City", kind='count',data=df, height=5, aspect=3 )
graph.set_xticklabels(rotation=90)
sns.set_theme(style="darkgrid")
graph=sns.catplot(x="City", kind='count',data=df,col="AQI_Bucket", col_wrap=2, height=3.5, aspect=3 )
graph.set_xticklabels(rotation=90)
graph1=sns.catplot(x="City", y="PM2.5", kind="box",data=df,height=5,aspect=3)
graph1.set_xticklabels(rotation=90)
graph2=sns.catplot(x="City", y="NO2", kind="box",data=df,height=5,aspect=3)
graph2.set_xticklabels(rotation=90)
graph3=sns.catplot(x="City", y="O3", kind="box",data=df,height=5,aspect=3)
graph3.set_xticklabels(rotation=90)
graph4=sns.catplot(x="City", y="SO2", kind="box",data=df,height=5,aspect=3)
graph4.set_xticklabels(rotation=90)
graph5=sns.catplot(x="AQI_Bucket", kind="count",data=df,height=6,aspect=3)
graph5.set_xticklabels(rotation=90)
# TO check the null values
df.isnull().sum().sort_values(ascending=False)
df.describe().loc['mean']
df=df.replace({
    "PM2.5":{np.nan: 67.476613},
    "PM10":{np.nan: 118.454435},
    "NO":{np.nan: 17.622421},
    "NO2":{np.nan: 28.978391},
    "NOx":{np.nan: 32.289012},
    "NH3":{np.nan: 23.848366},
    "CO":{np.nan: 2.345267},
    "SO2":{np.nan: 14.362933},
    "O3":{np.nan: 34.912885},
    "Benzene":{np.nan: 3.458668},
    "Toluene":{np.nan: 9.525714},
    "Xylene":{np.nan: 3.588683}
})
df.isnull().sum()
df=df.drop(['AQI_Bucket'],axis=1)
df.head()
sns.boxplot(data=df[['PM2.5','PM10']])
sns.boxplot(data=df[['NO2','NO','NOx','NH3']])
sns.boxplot(data=df[['O3','SO2']])
# IQR Method Q3 Q1
def replace_outliers(df):
    for column in df.select_dtypes(include=['number']).columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3-Q1
        lb = Q1 - 1.5 * IQR
        ub = Q3 + 1.5 * IQR
        df[column] = df[column].apply(lambda x : Q1 if x < lb else (Q3 if x > ub else x))
    return df
df=replace_outliers(df)
df.describe().T
sns.boxplot(data=df[['PM2.5','PM10']])
sns.boxplot(data=df[['O3','SO2']])
sns.boxplot(data=df[['Benzene','Toluene']])
sns.displot(df, x='AQI', color='red')
plt.show()
df1=df.drop(columns=['City'])
# Multivariate Analysis - Heatmap
#plt.figure(figsize=(12,8))
#sns.heatmap(df1.corr(),annot=True)
#plt.show()

plt.figure(figsize=(12,8))
sns.heatmap(df1.select_dtypes(include=['number']).corr(), annot=True, cmap="Pastel1")
plt.show()

# Week 3 - Data Modelling
df.drop(['Date','City'],axis=1,inplace=True)
df.head()
# Scaling - Standard scalar
from sklearn.preprocessing import StandardScaler
df1= StandardScaler().fit_transform(df)
df1
df = pd.DataFrame(df1, columns=df.columns)
df.head()
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error , r2_score

df.columns
X = df [['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3',
       'Benzene', 'Toluene', 'Xylene']]
y = df['AQI']
X.head()
# Split the data into training and testing data - Training set - 80% | Testing set - 20%
from sklearn.model_selection import train_test_split
X_train , X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
print('Shape of X Train',X_train.shape)
print('Shape of X Test',X_test.shape)
print('Shape of y Train',y_train.shape)
print('Shape of y Test',y_test.shape)

# Linear Regression
LR = LinearRegression()
LR.fit(X_train,y_train)
# Predicting the values
train_pred = LR.predict(X_train)
test_pred = LR.predict(X_test)

# Evaluation for linear Regression
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ',str(RMSE_train))
print('RMSE Test Data = ',str(RMSE_test))
print('_'*60)
print('R Squared value for train = ',LR.score(X_train,y_train))
print('R Squared value on test = ',LR.score(X_test ,y_test))

# KNN 
knn = KNeighborsRegressor()
knn.fit(X_train,y_train)
# Predicting the values
train_pred = knn.predict(X_train)
test_pred = knn.predict(X_test)

# Evaluation for KNN
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ',str(RMSE_train))
print('RMSE Test Data = ',str(RMSE_test))
print('_'*60)
print('R Squared value for train = ',knn.score(X_train,y_train))
print('R Squared value on test = ',knn.score(X_test ,y_test))
# Decision Tree 
dtr = DecisionTreeRegressor()
dtr.fit(X_train,y_train)
# Predicting the values
train_pred = dtr.predict(X_train)
test_pred = dtr.predict(X_test)

# Evaluation for Decison Tree Regression
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ',str(RMSE_train))
print('RMSE Test Data = ',str(RMSE_test))
print('_'*60)
print('R Squared value for train = ',dtr.score(X_train,y_train))
print('R Squared value on test = ',dtr.score(X_test ,y_test))
# Random Forest Regressor
rfr = RandomForestRegressor()
rfr.fit(X_train,y_train)

# Predicting the values
train_pred = rfr.predict(X_train)
test_pred = rfr.predict(X_test)

# Evaluation for Random Forest Regressor
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ',str(RMSE_train))
print('RMSE Test Data = ',str(RMSE_test))
print('_'*60)
print('R Squared value for train = ',rfr.score(X_train,y_train))
print('R Squared value on test = ',rfr.score(X_test ,y_test))
